{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: \n",
    "Take one of the supervised learning models you have built recently and apply at least three dimensionality reduction techniques to it (separately). Be sure to create a short summary of each technique you use. Indicate how each changed the model performance. \n",
    "Reference:\n",
    "https://machinelearningmastery.com/dimensionality-reduction-algorithms-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Truncated SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#import the data file and write out each row into a csv file\n",
    "with open(\"../WeeklyHomework/abalone.data\") as infile, open(\"abalone.csv\", \"w\") as outfile:\n",
    "    csv_writer = csv.writer(outfile)\n",
    "    prev = ''\n",
    "    csv_writer.writerow(['Sex', 'Length', 'Diameter', 'Height', 'Whole Weight', 'Shucked Weight', 'Viscera Weight', 'Shell Weight', 'Rings'])\n",
    "    for line in infile:\n",
    "        row = [field.strip() for field in line.split(',')]\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole Weight  Shucked Weight  Viscera Weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell Weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#load the abalone dataset from csv file and save as a pandas dataframe\n",
    "abalone_df = pd.read_csv('./abalone.csv')\n",
    "abalone_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Outliers from the Dataset\n",
    "# calculate summary statistics\n",
    "data_mean, data_std = np.mean(abalone_df['Rings']), np.std(abalone_df['Rings'])\n",
    "# identify outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify outliers\n",
    "outliers = [x for x in abalone_df['Rings'] if x < lower or x > upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4115.000000\n",
       "mean        9.758931\n",
       "std         2.904193\n",
       "min         1.000000\n",
       "25%         8.000000\n",
       "50%         9.000000\n",
       "75%        11.000000\n",
       "max        19.000000\n",
       "Name: Rings, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove outliers\n",
    "abalone_df = abalone_df[(abalone_df['Rings'] > lower) & (abalone_df['Rings'] < upper)]\n",
    "abalone_df['Rings'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the predictor variables into the dataframe X\n",
    "X = abalone_df.drop('Rings', axis=1)\n",
    "#save the independent variable y\n",
    "y = abalone_df['Rings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform OneHotEncoding on only the 'Sex' Column to turn it into a numerical column instead of a categorical column. Drop the first column since it is repetitive data. \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer([(\"Sex\", OneHotEncoder(drop='first'), [0])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Standardize the dataset\n",
    "sc = StandardScaler()\n",
    "X_res= sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename X and y to predictors and target for convention\n",
    "predictors=X\n",
    "target=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "svd = TruncatedSVD(n_components=5)\n",
    "\n",
    "predictors=svd.fit_transform(predictors)\n",
    "\n",
    "#clr=LogisticRegression(random_state=42).fit(X_test_svd, y_test)\n",
    "#print(clr.score(X_test_svd, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#get the number of columns in the predictors array\n",
    "n_cols = predictors.shape[1]\n",
    "print(n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "90/90 [==============================] - 2s 8ms/step - loss: 50.2255 - val_loss: 5.8921\n",
      "Epoch 2/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 6.1295 - val_loss: 5.4570\n",
      "Epoch 3/40\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 5.6388 - val_loss: 5.4890\n",
      "Epoch 4/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 5.4401 - val_loss: 5.0120\n",
      "Epoch 5/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 5.6633 - val_loss: 4.8990\n",
      "Epoch 6/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4509 - val_loss: 4.7198\n",
      "Epoch 7/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 5.4383 - val_loss: 4.6497\n",
      "Epoch 8/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.7885 - val_loss: 4.5450\n",
      "Epoch 9/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 5.0717 - val_loss: 4.4438\n",
      "Epoch 10/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.9627 - val_loss: 4.3821\n",
      "Epoch 11/40\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 5.0935 - val_loss: 4.3805\n",
      "Epoch 12/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0156 - val_loss: 4.2919\n",
      "Epoch 13/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6013 - val_loss: 4.5484\n",
      "Epoch 14/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.3379 - val_loss: 4.3279\n",
      "Epoch 15/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.6932 - val_loss: 4.0356\n",
      "Epoch 16/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1935 - val_loss: 4.0497\n",
      "Epoch 17/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.4161 - val_loss: 3.9637\n",
      "Epoch 18/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 4.2883 - val_loss: 3.8963\n",
      "Epoch 19/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.3077 - val_loss: 3.8656\n",
      "Epoch 20/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 4.3217 - val_loss: 3.8478\n",
      "Epoch 21/40\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 4.3036 - val_loss: 3.7967\n",
      "Epoch 22/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2352 - val_loss: 3.7967\n",
      "Epoch 23/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 4.2168 - val_loss: 3.7648\n",
      "Epoch 24/40\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 4.3037 - val_loss: 4.2472\n",
      "Epoch 25/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1246 - val_loss: 3.9373\n",
      "Epoch 26/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0710 - val_loss: 3.8834\n",
      "Epoch 27/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.0967 - val_loss: 3.7279\n",
      "Epoch 28/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.8916 - val_loss: 3.9073\n",
      "Epoch 29/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.1673 - val_loss: 3.7621\n",
      "Epoch 30/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.8427 - val_loss: 3.6964\n",
      "Epoch 31/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.9703 - val_loss: 3.6597\n",
      "Epoch 32/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.8699 - val_loss: 3.8495\n",
      "Epoch 33/40\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 4.0656 - val_loss: 3.7958\n",
      "Epoch 34/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1774 - val_loss: 3.7868\n",
      "Epoch 35/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.9467 - val_loss: 3.6764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26b4e524910>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the keras model\n",
    "model=Sequential()\n",
    "\n",
    "#add the layers \n",
    "model.add(Dense(200, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer=SGD(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "#set an early stopping monitor so that the model will stop running if improvement to the loss function is not seen after a specified number of epochs\n",
    "early_stopping_monitor = EarlyStopping(patience=4)\n",
    "\n",
    "#fit the model\n",
    "model.fit(predictors, target, validation_split=0.3, epochs=40, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9130342391081243\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(3.6597)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated SVD is a good reduction technique when you have a sparse dataset. It stands for singular value decomposition. Using this method, I got a rmse of 1.91, which is slightly worse than when I used keras without dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = pca.fit_transform(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename X and y to predictors and target for convention\n",
    "predictors=X_reduced\n",
    "target=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#get the number of columns in the predictors array\n",
    "n_cols = predictors.shape[1]\n",
    "print(n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "90/90 [==============================] - 3s 24ms/step - loss: 57.3541 - val_loss: 5.8324\n",
      "Epoch 2/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6270 - val_loss: 4.1313\n",
      "Epoch 3/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1388 - val_loss: 4.0570\n",
      "Epoch 4/40\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 4.2224 - val_loss: 3.8812\n",
      "Epoch 5/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1968 - val_loss: 3.8905\n",
      "Epoch 6/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.7355 - val_loss: 3.7465\n",
      "Epoch 7/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8083 - val_loss: 3.7613\n",
      "Epoch 8/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.8003 - val_loss: 3.7017\n",
      "Epoch 9/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.9583 - val_loss: 3.7012\n",
      "Epoch 10/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.6303 - val_loss: 3.6586\n",
      "Epoch 11/40\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 3.8070 - val_loss: 3.7524\n",
      "Epoch 12/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.8614 - val_loss: 3.7738\n",
      "Epoch 13/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7760 - val_loss: 3.6844\n",
      "Epoch 14/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.7790 - val_loss: 3.6525\n",
      "Epoch 15/40\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 3.8562 - val_loss: 3.5981\n",
      "Epoch 16/40\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.7272 - val_loss: 3.6218\n",
      "Epoch 17/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8759 - val_loss: 3.6733\n",
      "Epoch 18/40\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7396 - val_loss: 3.5384\n",
      "Epoch 19/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.7120 - val_loss: 3.5443\n",
      "Epoch 20/40\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.3465 - val_loss: 3.5423\n",
      "Epoch 21/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.5326 - val_loss: 3.5691\n",
      "Epoch 22/40\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.5940 - val_loss: 3.6986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26b48ed88b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the keras model\n",
    "model=Sequential()\n",
    "\n",
    "#add the layers \n",
    "model.add(Dense(200, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer=SGD(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "#set an early stopping monitor so that the model will stop running if improvement to the loss function is not seen after a specified number of epochs\n",
    "early_stopping_monitor = EarlyStopping(patience=4)\n",
    "\n",
    "#fit the model\n",
    "model.fit(predictors, target, validation_split=0.3, epochs=40, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8820998910791107\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(3.5423)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a reduction technique that works well with dense data, meaning there are few missing values.  It reduces dimensions of the data by finding the principal component, which is a eigenvector of the data's covariance matrix that maximizes the variance from X.  The next prinipal component is perpendicular to the first eigenvector meaning they are uncorrelated.  This technique gave me the lowest rmse that I have gotten for the abalone dataset so far, 1.88. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. NMF (Non-Negative Matrix Factorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=5, init='random', random_state=42)\n",
    "X_new = model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename X and y to predictors and target for convention\n",
    "predictors=X_new\n",
    "target=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#get the number of columns in the predictors array\n",
    "n_cols = predictors.shape[1]\n",
    "print(n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 58.2650 - val_loss: 4.6858\n",
      "Epoch 2/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7367 - val_loss: 4.0710\n",
      "Epoch 3/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 3.9825 - val_loss: 3.9471\n",
      "Epoch 4/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 4.0470 - val_loss: 3.9124\n",
      "Epoch 5/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 3.9422 - val_loss: 3.8918\n",
      "Epoch 6/70\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 4.0843 - val_loss: 3.8906\n",
      "Epoch 7/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0429 - val_loss: 3.8816\n",
      "Epoch 8/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 3.7194 - val_loss: 4.0044\n",
      "Epoch 9/70\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.8662 - val_loss: 3.8785\n",
      "Epoch 10/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9736 - val_loss: 3.8618\n",
      "Epoch 11/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8236 - val_loss: 3.9821\n",
      "Epoch 12/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 4.0914 - val_loss: 3.8055\n",
      "Epoch 13/70\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.5375 - val_loss: 3.8048\n",
      "Epoch 14/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0346 - val_loss: 3.7938\n",
      "Epoch 15/70\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.7961 - val_loss: 3.8093\n",
      "Epoch 16/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7271 - val_loss: 3.7929\n",
      "Epoch 17/70\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.9454 - val_loss: 3.7539\n",
      "Epoch 18/70\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.6870 - val_loss: 4.1293\n",
      "Epoch 19/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 4.0347 - val_loss: 3.7449\n",
      "Epoch 20/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9273 - val_loss: 3.8018\n",
      "Epoch 21/70\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.9693 - val_loss: 3.7447\n",
      "Epoch 22/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 4.0220 - val_loss: 3.7477\n",
      "Epoch 23/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9825 - val_loss: 3.7303\n",
      "Epoch 24/70\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.6765 - val_loss: 3.7412\n",
      "Epoch 25/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 3.6720 - val_loss: 3.7303\n",
      "Epoch 26/70\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.5530 - val_loss: 3.7825\n",
      "Epoch 27/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6881 - val_loss: 3.7023\n",
      "Epoch 28/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8815 - val_loss: 3.9101\n",
      "Epoch 29/70\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.6171 - val_loss: 4.0781\n",
      "Epoch 30/70\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.8741 - val_loss: 3.6798\n",
      "Epoch 31/70\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.7839 - val_loss: 3.6976\n",
      "Epoch 32/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 3.7461 - val_loss: 3.6679\n",
      "Epoch 33/70\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.6363 - val_loss: 3.6525\n",
      "Epoch 34/70\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.7806 - val_loss: 3.6727\n",
      "Epoch 35/70\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.8327 - val_loss: 3.6414\n",
      "Epoch 36/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5347 - val_loss: 3.7594\n",
      "Epoch 37/70\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.6241 - val_loss: 3.8580\n",
      "Epoch 38/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6754 - val_loss: 3.6454\n",
      "Epoch 39/70\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.9157 - val_loss: 3.6649\n",
      "Epoch 40/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 3.9588 - val_loss: 3.6510\n",
      "Epoch 41/70\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.8288 - val_loss: 3.6259\n",
      "Epoch 42/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 3.5962 - val_loss: 3.6587\n",
      "Epoch 43/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7589 - val_loss: 3.8323\n",
      "Epoch 44/70\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 3.6835 - val_loss: 3.6168\n",
      "Epoch 45/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6496 - val_loss: 3.6125\n",
      "Epoch 46/70\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 3.6975 - val_loss: 3.6805\n",
      "Epoch 47/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4404 - val_loss: 3.6576\n",
      "Epoch 48/70\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.9124 - val_loss: 3.6351\n",
      "Epoch 49/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6981 - val_loss: 3.6652\n",
      "Epoch 50/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9614 - val_loss: 3.7017\n",
      "Epoch 51/70\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4476 - val_loss: 3.6969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26b4fed2910>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the keras model\n",
    "model=Sequential()\n",
    "\n",
    "#add the layers \n",
    "model.add(Dense(200, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer=SGD(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "#set an early stopping monitor so that the model will stop running if improvement to the loss function is not seen after a specified number of epochs\n",
    "early_stopping_monitor = EarlyStopping(patience=6)\n",
    "\n",
    "#fit the model\n",
    "model.fit(predictors, target, validation_split=0.3, epochs=70, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9065938214522777\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(3.6351)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Negative Matrix Factorization is another reduction technique that works for non-negative datasets.  This also gave me a similar rmse to when I used keras alone for the abalone dataset, 1.90."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.\n",
    "Write a function that will indicate if an inputted IPv4 address is accurate or not.\n",
    "IP addresses are valid if they have 4 values between 0 and 255 (inclusive), punctuated\n",
    "by periods.\n",
    "Input 1:\n",
    "2.33.245.5\n",
    "Output 1:\n",
    "True\n",
    "Input 2:\n",
    "12.345.67.89\n",
    "Output 2:\n",
    "False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_ip(ip_address):\n",
    "    try:\n",
    "        parts = ip_address.split('.')\n",
    "        for x in parts:\n",
    "            if int(x)<0 or int(x)>255 or len(parts) != 4:\n",
    "                return False\n",
    "            else:\n",
    "                continue\n",
    "    except:\n",
    "        print(\"IP Address should be a string with values punctuated by periods.  This IP address doesn't have periods.\")\n",
    "        return False\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP Address should be a string with values punctuated by periods.  This IP address doesn't have periods.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ip('2,33,255,5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ip('2.33.245.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ip('12.345.67.89')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
