{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write simple (straightforward) definitions for the following parameters for RandomForestClassifier\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and indicate how they correlate with the precision and recall for the basic\n",
    "diabetes model we built in class. You will need to rerun the model multiple times to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitons:\n",
    "estimators: the number of models to use in the random forest classifier. \n",
    "max_depth: the maximum depth of the tree.  This is the number of nodes from the root node down to the leaf following the longest path. \n",
    "\n",
    "min_samples_split: this is the minimum number of samples (data points) required to split the node.  Each node asks a question about the data and evaluates that question on data points.  This parameter checks to see how many data points are being evaluated and only splits the node if that number is present. \n",
    "\n",
    "min_samples_leaf: This is the minimum number of samples required to be a leaf.  A leaf is the final node of the tree which represents a class.\n",
    "\n",
    "min_weight_fraction_leaf: Each leaf node has a weight of the total weights of all the leaves.  If this is specified, it means that every leaf must have at least the weight specified.\n",
    "\n",
    "max_leaf_nodes: This specifies the maximum number of leaf nodes that are possible in the decision tree.  If this is unspecified, a maximum number of leaf nodes is possible.  If it is specified, then the model will pick the leaves that gain the maximum information. \n",
    "\n",
    "min_impurity_decrease: impurity is the chance that an outcome would be incorrectly labeled by a specifically node.  If a minimum impurity decrease value is set, it means that a node will be split into a further node if it decreases impurity more than the minimum value set. \n",
    "\n",
    "min_impurity_split: This is a threshold value that determines whether a node will be split or become a leaf node, depending on whether the impurity of the node is above this threshold (whether the node will incorrecly classify a certain percentage of the samples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "diabetes_df = pd.read_csv(\"../week_13/diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "0.7610055001359349\n",
      "0.7662337662337663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state =42)\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred, average='weighted'))\n",
    "print(recall_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_with_estimators(n_est):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7473701821527908, 0.7532467532467533)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_with_estimators(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_estimators = [10, 20, 30, 50, 100, 150, 200, 250, 300]\n",
    "precision_recall_list = list(map(lambda x: corr_with_estimators(x), list_of_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = [x[0] for x in precision_recall_list]\n",
    "recall = [x[1] for x in precision_recall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7251114954546856, 0.7349148493016417, 0.7473701821527908, 0.7538901465506971, 0.7473701821527908, 0.7610055001359349, 0.7610055001359349, 0.7545792843068642, 0.7545792843068642]\n",
      "[0.7337662337662337, 0.7402597402597403, 0.7532467532467533, 0.7597402597402597, 0.7532467532467533, 0.7662337662337663, 0.7662337662337663, 0.7597402597402597, 0.7597402597402597]\n"
     ]
    }
   ],
   "source": [
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between estimators and precision is 0.6738727856361035\n",
      "The correlation between estimators and recall is 0.6679749434076905\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "correlation, p_value = pearsonr(list_of_estimators, precision)\n",
    "print(\"The correlation between estimators and precision is \" + str(correlation))\n",
    "\n",
    "correlation, p_value = pearsonr(list_of_estimators, recall)\n",
    "print(\"The correlation between estimators and recall is \" + str(correlation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_with_max_depth(max_d):\n",
    "    rf = RandomForestClassifier(n_estimators=200, max_depth=max_d, random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_max_depths = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\n",
    "precision_recall_list = list(map(lambda x: corr_with_max_depth(x), list_of_max_depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = [x[0] for x in precision_recall_list]\n",
    "recall = [x[1] for x in precision_recall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between max_depth and precision is 0.8279812237900358\n",
      "The correlation between max_depth and recall is 0.850321470558266\n"
     ]
    }
   ],
   "source": [
    "correlation, p_value = pearsonr(list_of_max_depths, precision)\n",
    "print(\"The correlation between max_depth and precision is \" + str(correlation))\n",
    "\n",
    "correlation, p_value = pearsonr(list_of_max_depths, recall)\n",
    "print(\"The correlation between max_depth and recall is \" + str(correlation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_with_min_samples_split(min_ss):\n",
    "    rf = RandomForestClassifier(n_estimators=200, min_samples_split=min_ss, random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_min_samples_split = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40, 50]\n",
    "precision_recall_list = list(map(lambda x: corr_with_min_samples_split(x), list_of_min_samples_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = [x[0] for x in precision_recall_list]\n",
    "recall = [x[1] for x in precision_recall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between min_samples_split and precision is -0.9373147401219183\n",
      "The correlation between min_samples_split and recall is -0.9277873584477501\n"
     ]
    }
   ],
   "source": [
    "correlation, p_value = pearsonr(list_of_min_samples_split, precision)\n",
    "print(\"The correlation between min_samples_split and precision is \" + str(correlation))\n",
    "\n",
    "correlation, p_value = pearsonr(list_of_min_samples_split, recall)\n",
    "print(\"The correlation between min_samples_split and recall is \" + str(correlation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_with_min_samples_leaf(min_sl):\n",
    "    rf = RandomForestClassifier(n_estimators=200, min_samples_leaf=min_sl, random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_min_samples_leaf = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40, 50]\n",
    "precision_recall_list = list(map(lambda x: corr_with_min_samples_leaf(x), list_of_min_samples_leaf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = [x[0] for x in precision_recall_list]\n",
    "recall = [x[1] for x in precision_recall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between min_samples_leaf and precision is -0.543867975157251\n",
      "The correlation between min_samples_leaf and recall is -0.5268862526734289\n"
     ]
    }
   ],
   "source": [
    "correlation, p_value = pearsonr(list_of_min_samples_leaf, precision)\n",
    "print(\"The correlation between min_samples_leaf and precision is \" + str(correlation))\n",
    "\n",
    "correlation, p_value = pearsonr(list_of_min_samples_leaf, recall)\n",
    "print(\"The correlation between min_samples_leaf and recall is \" + str(correlation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_with_min_weight_fraction_leaf(min_w):\n",
    "    rf = RandomForestClassifier(n_estimators=200, min_weight_fraction_leaf=min_w, random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "list_of_min_weight_fraction_leaf = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "precision_recall_list = list(map(lambda x: corr_with_min_weight_fraction_leaf(x), list_of_min_weight_fraction_leaf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = [x[0] for x in precision_recall_list]\n",
    "recall = [x[1] for x in precision_recall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between min_weight_fraction_leaf and precision is -0.7362889364195605\n",
      "The correlation between min_weight_fraction_leaf and recall is -0.8988991088231968\n"
     ]
    }
   ],
   "source": [
    "correlation, p_value = pearsonr(list_of_min_weight_fraction_leaf, precision)\n",
    "print(\"The correlation between min_weight_fraction_leaf and precision is \" + str(correlation))\n",
    "\n",
    "correlation, p_value = pearsonr(list_of_min_weight_fraction_leaf, recall)\n",
    "print(\"The correlation between min_weight_fraction_leaf and recall is \" + str(correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_with_max_leaf_nodes(max_leaf):\n",
    "    rf = RandomForestClassifier(n_estimators=200, max_leaf_nodes=max_leaf, random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_max_leaf_nodes = [2, 3, 4, 5, 6, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "precision_recall_list = list(map(lambda x: corr_with_max_leaf_nodes(x), list_of_max_leaf_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = [x[0] for x in precision_recall_list]\n",
    "recall = [x[1] for x in precision_recall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between max_leaf_nodes and precision is 0.5000049538344156\n",
      "The correlation between max_leaf_nodes and recall is 0.6347010628362819\n"
     ]
    }
   ],
   "source": [
    "correlation, p_value = pearsonr(list_of_max_leaf_nodes, precision)\n",
    "print(\"The correlation between max_leaf_nodes and precision is \" + str(correlation))\n",
    "\n",
    "correlation, p_value = pearsonr(list_of_max_leaf_nodes, recall)\n",
    "print(\"The correlation between max_leaf_nodes and recall is \" + str(correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_with_min_impurity_decrease(min_imp):\n",
    "    rf = RandomForestClassifier(n_estimators=200, min_impurity_decrease=min_imp, random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "list_of_min_impurity_decrease = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "precision_recall_list = list(map(lambda x: corr_with_min_impurity_decrease(x), list_of_min_impurity_decrease))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = [x[0] for x in precision_recall_list]\n",
    "recall = [x[1] for x in precision_recall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between min_impurity_decrease and precision is -0.5\n",
      "The correlation between min_impurity_decrease and recall is -0.49999999999999994\n"
     ]
    }
   ],
   "source": [
    "correlation, p_value = pearsonr(list_of_min_impurity_decrease, precision)\n",
    "print(\"The correlation between min_impurity_decrease and precision is \" + str(correlation))\n",
    "\n",
    "correlation, p_value = pearsonr(list_of_min_impurity_decrease, recall)\n",
    "print(\"The correlation between min_impurity_decrease and recall is \" + str(correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_with_min_impurity_split(min_imp_spl):\n",
    "    rf = RandomForestClassifier(n_estimators=200, min_impurity_split=min_imp_spl, random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "list_of_min_impurity_split = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "precision_recall_list = list(map(lambda x: corr_with_min_impurity_split(x), list_of_min_impurity_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = [x[0] for x in precision_recall_list]\n",
    "recall = [x[1] for x in precision_recall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between min_impurity_split and precision is -0.8853585906752075\n",
      "The correlation between min_impurity_split and recall is -0.9192718348789796\n"
     ]
    }
   ],
   "source": [
    "correlation, p_value = pearsonr(list_of_min_impurity_split, precision)\n",
    "print(\"The correlation between min_impurity_split and precision is \" + str(correlation))\n",
    "\n",
    "correlation, p_value = pearsonr(list_of_min_impurity_split, recall)\n",
    "print(\"The correlation between min_impurity_split and recall is \" + str(correlation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter | Correlation with Precision | Correlation with Recall\n",
    "-|-|-\n",
    "estimators | 0.674 | 0.668\n",
    "max_depth | 0.828 | 0.850\n",
    "min_samples_split | -0.937 | -0.928\n",
    "min_samples_leaf | -0.544 | -0.527\n",
    "min_weight_fraction_leaf | -0.736 | -0.899\n",
    "max_leaf_nodes | 0.500 | 0.635\n",
    "min_impurity_decrease | -0.500 | -0.499\n",
    "min_impurity_split | -0.885 | -0.919\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. How does setting bootstrap=False influence the model performance? Note: the default is bootstrap=True. Explain why your results might be so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "0.7610055001359349\n",
      "0.7662337662337663\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, random_state =42)\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred, average='weighted'))\n",
    "print(recall_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       100\n",
      "           1       0.67      0.59      0.63        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.72      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "0.7483459936290124\n",
      "0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, bootstrap=False, random_state =42)\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred, average='weighted'))\n",
    "print(recall_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When bootstrap was set to false, model performance decreased.  The precision score went from 0.761 to 0.748 and the recall score went from 0.766 to 0.753.  When bootstrapping is on, it runs the model on multiple random sample sets of the dataset with replacement.  This can remove the effects of outliers because you are only taking a sample of the entire population multiple times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
